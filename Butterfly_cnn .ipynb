{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9382a113-acd1-462f-a42c-889a1b5f66a4",
   "metadata": {},
   "source": [
    "# Butterfly Cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e8c3e7-3c8f-426c-aece-fe4fb3a04e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5510e35f-7a94-4f54-9404-73f4ae8ded44",
   "metadata": {},
   "source": [
    "## importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac27d8be-961e-4479-aeab-8706188f4f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in datasets\n",
    "train_df = pd.read_csv('Resources/Training_set.csv')\n",
    "test_df = pd.read_csv('Resources/Testing_set.csv')\n",
    "train_path = 'Resources/train/'\n",
    "test_path = 'Resources/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5b5a43-c727-4f66-8db7-0d018a4c4433",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The data was split into train and test sets and I would like to have it just be one dataset\n",
    "butterfly_df = pd.concat([train_df, test_df], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aec1988-6ae5-4772-a57a-fbbe477092ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "butterfly_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af653065-02f5-4764-89a4-c13825e17613",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before moving forward I need to also combine the train and test folder for the images\n",
    "#But I also need to make sure each image is correctly placed with the right label\n",
    "# Initialize list to store images\n",
    "images = []\n",
    "\n",
    "# Loop through each entry in the combined DataFrame\n",
    "for i in range(len(butterfly_df)):\n",
    "    filename = butterfly_df.iloc[i, 0]\n",
    "    \n",
    "    if i < len(train_df):\n",
    "        path = train_path + filename  # First part of butterfly_df is from train_df\n",
    "    else:\n",
    "        path = test_path + filename   # Second part of butterfly_df is from test_df\n",
    "\n",
    "    print(f'{i+1} of {len(butterfly_df)}: Attempting to import {filename}')\n",
    "    \n",
    "    try:\n",
    "        # Open, add image to list, and close to free up file handle\n",
    "        with Image.open(path) as img:\n",
    "            images.append(img.copy())\n",
    "    except Exception as e:\n",
    "        print(f'FAILED to load {filename}: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b93379-8422-48c4-bb6c-6510a0bfb09e",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74d85e4-572b-42a0-9600-b0d31cd5da6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a random image from the list to ensure the import was successful\n",
    "images[6543]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d9ebd0-90f0-45fa-a82f-b5953d56e86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the size of the second image\n",
    "images[1].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc87798-cba5-4cff-aecb-873be4d1cf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if I need to make it smaller if my machine is not up to par for doing it with 224 by 224.\n",
    "#it will be more accurate at that size though. Also can do 128 by 128\n",
    "\n",
    "# Get all the sizes into a list, then convert to a set\n",
    "sizes = set([img.size for img in images])\n",
    "sizes\n",
    "# Use a for loop to resize all images to 64 by 60\n",
    "target_size = (128, 128)\n",
    "\n",
    "resized_images = [img.resize(target_size, resample = Image.LANCZOS) for img in images]\n",
    "resized_images[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53ef681-822d-44b3-ae5f-1bc6a24aedbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all images to floating point numpy arrays\n",
    "float_images = [np.array(img).astype(np.float32) for img in resized_images]\n",
    "\n",
    "# Display the pixel values of the first image\n",
    "print(\"Pixel Values:\")\n",
    "print(float_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fb6103-8a40-4dd3-935e-4d5898da8085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To normalize images to a range between 0 and 1,\n",
    "# we need to divide all pixel values by the max of 255\n",
    "\n",
    "normalized_images = [img/255 for img in float_images]\n",
    "\n",
    "# Display the pixel values of the first image\n",
    "print(\"Pixel Values:\")\n",
    "print(normalized_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d22a91-8149-491d-8900-308bdada597d",
   "metadata": {},
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bffda3-94c5-4c1d-9253-b5dc036808dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first few image filenames\n",
    "butterfly_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7f67d1-1ef3-4c1b-b05a-e63ffe01118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, remove the .jpg file extension, then split into new columns. \n",
    "# Remove the .jpg extension\n",
    "butterfly_df['filename'] = butterfly_df['filename'].str.replace('.jpg', '', regex=False)\n",
    "butterfly_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11587750-1e35-4be8-9c57-af41797ef9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can call our preprocessed pixel data 'X'\n",
    "X = normalized_images\n",
    "\n",
    "# For our purposes, we'll select the userid column as 'y'\n",
    "y = butterfly_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd3cb4d-c3a7-44ab-9291-f7e500b2efd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the total number of classes\n",
    "y.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9775d03b-d622-4520-a976-82e12e648e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c222c9-94b4-498f-98ac-d683a7de3eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we'll split our data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed3355b-3cf0-41bb-8836-bd32b0a8ffa8",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e895074-a21f-4a0b-bf61-baa030061c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply augmentation to the whole training dataset\n",
    "# Define the augmentation pipeline\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomRotation(0.2),         # Randomly rotate images by 20%\n",
    "    tf.keras.layers.RandomTranslation(0.2, 0.2), # Randomly shift images horizontally and vertically by 20%\n",
    "    tf.keras.layers.RandomZoom(0.3),             # Randomly zoom images by up to 30%\n",
    "    tf.keras.layers.RandomFlip('horizontal'),    # Random horizontal flip\n",
    "    tf.keras.layers.RandomContrast(0.2)          # Random contrast adjustment\n",
    "])\n",
    "\n",
    "# Create variables to hold the X and y training data\n",
    "X_train_aug = []\n",
    "y_train_aug = []\n",
    "\n",
    "# Loop through all the images.\n",
    "for i in range(len(X_train)):\n",
    "    # Select the image\n",
    "    img = X_train[i]\n",
    "    # Select the label from the training data\n",
    "    label = y_train[i]\n",
    "\n",
    "    # Ensure that the input data has the correct shape\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Add 5 images for every original image\n",
    "    for j in range(5):\n",
    "        # Append a new image to the X list\n",
    "        X_train_aug.append(data_augmentation(img, training=True)[0].numpy())\n",
    "        # Append the label for the original image to the y list\n",
    "        y_train_aug.append(label)\n",
    "\n",
    "# Print the length of each list\n",
    "print(len(X_train_aug))\n",
    "print(len(y_train_aug))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8dbc5b-953c-44a4-8e59-57c8f27aee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape test data for the model\n",
    "X_test_np = []\n",
    "for img in X_test:\n",
    "    # Append the image to the list\n",
    "    X_test_np.append(img)\n",
    "\n",
    "# Convert to numpy array\n",
    "X_test_np = np.array(X_test_np)\n",
    "\n",
    "# Check the shape of the first image\n",
    "X_test_np[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af21a02-1e31-4b6e-9458-63db749a22d8",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ecd24b-8a25-427a-8a95-017088f8c3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode the y data\n",
    "y_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False).fit(np.array(y_train_aug).reshape(-1, 1))\n",
    "y_train_aug_enc = y_encoder.transform(np.array(y_train_aug).reshape(-1, 1))\n",
    "y_test_enc = y_encoder.transform(np.array(y_test).reshape(-1, 1))\n",
    "\n",
    "# Convert values to numpy arrays\n",
    "X_train_aug_np = np.array(X_train_aug)\n",
    "X_test_np = np.array(X_test_np)\n",
    "y_train_aug_np = np.array(y_train_aug_enc)\n",
    "y_test_np = np.array(y_test_enc)\n",
    "\n",
    "# Load and preprocess your CMU Face Images dataset (Ensure each image is labeled as \"with sunglasses\" or \"without sunglasses\")\n",
    "# The following code assumes that you have already loaded and preprocessed your dataset into 'X' and 'y' (features and labels).\n",
    "\n",
    "# Split the training dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_aug_np, y_train_aug_np, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the total number of one_hot_encoded columns\n",
    "np.array(y_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc0f170-4d1a-40b0-8e24-37ddf73ce409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a CNN model\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.2),  # Dropout layer with 20% dropout rate\n",
    "\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.3),  # Dropout layer with 30% dropout rate\n",
    "\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    \n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.4),  # Dropout layer with 40% dropout rate\n",
    "\n",
    "    layers.Dense(76, activation='sigmoid')  # Output layer for 76 classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping with patience of 3 epochs\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09384cb5-4b65-4d47-97a4-eec291a17847",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the model\n",
    "model.evaluate(X_test_np, y_test_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e268273-d894-4676-84e9-bae9f7717a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model(\"butterfly_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
